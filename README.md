# 👋 Hey there, I’m Mauricio V

Welcome to my GitHub.

Currently, I am developing a memory-driven, modular, local-first AI assistant system that uses several LLMs on my own hardware and operates completely offline. It has persistent memory logs, GPU/RAM-aware orchestration, and complete routing logic.

---

## 🧩 Core Projects

- **Multi-Model Chaining**  
  Routed Capybara → OpenChat_3.5  for task-specific coordination  
- **Memory Parser + Watcher System**  
  Custom Python scripts (`parser.py`, `watcher.py`) that process memory logs in `.json`/`.md`, summarize tone, emotion, and intent  
- **Docker-Based AI Stack**  
  Running Ollama, Open Web UI, and `n8n` in isolated containers  
- **Live Remote Access**  
  Cloudflare tunnel connects Open Web UI to a secure public domain

---

## ⚙️ In Progress

- **SkyWatcher**  
  Pulls live data from `api.nasa.gov` (meteors, comets, etc) → parsed into LLM for insight logging  
- **Voice Transcriber + LLM Feedback Loop**  
  Captures real-time audio → transcribes → routes to LLM → provides live context and suggestions  
- **Auto-Reel Downloader**  
  Local script for auto-downloading Instagram saved reels using headless methods

---

## 🎥 [Watcher & Parser Demo (2 min)](https://m.youtube.com/watch?v=XArldnlAzNk&feature=youtu.be)

A core piece of my offline AI system in motion — local memory logs being parsed and processed in real time.

---

## 🤖 [Use My Custom GPT Assistant](https://chatgpt.com/g/g-686d56d1a8048191bd32fdb5704d2eb4-memoryarchitect-gpt)

This GPT helps me coordinate LLMs, debug flows, and optimize model behavior. It exists because I needed help managing the complexity — so I built something that *could*.

---

## 🎞️ Live Demo Preview

Here’s a sneak peek of my local AI system processing memory logs in real time:

<!-- Replace 'your-demo.gif' with actual filename -->

---

## 🔧 My Current Stack

`Python`, `FastAPI`, `Gradio`, `Docker`, `Ollama`, `LM Studio`, `OpenAI`, `n8n`, `Cloudflare Tunnel`, `Whisper`, `JSON`, `Markdown`, `Bash`, `FileWatcher`

---

## 🌱 What’s Next

- Web dashboard for routing and GPU control
- Live Whisper + Ollama voice-to-memory pipeline
- MFA-secured VPN access for remote model orchestration
- Modular Docker nodes for future plugin-style tools

---

## 🪪 [Connect with Me on LinkedIn](https://www.linkedin.com/in/mauricio-ventura-52a14425a/)

Thanks for stopping by. I’m just getting started. ✌️
